{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets.ravdess import Ravdess\n",
    "dataset = Ravdess(\"datasets/ravdess/train/train.csv\",\"datasets/ravdess/train/audios\")\n",
    "\n",
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Speed\n",
    "from torch.utils.data import DataLoader\n",
    "# from datasets.utils import collate_fn\n",
    "import torch \n",
    "def collate_padded(batch):\n",
    "    tensors, targets = [], []\n",
    "    for wave, label in batch:\n",
    "        tensors += [wave]\n",
    "        targets += [label]\n",
    "    \n",
    "    tensor_padded = torch.nn.utils.rnn.pad_sequence(tensors, batch_first = True)\n",
    "    return tensor_padded , targets\n",
    "\n",
    "loader = DataLoader(dataset, 128, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 8000])\n",
      "torch.Size([128, 8, 8000])\n"
     ]
    }
   ],
   "source": [
    "it = iter(loader)\n",
    "wave,_ = next(it)\n",
    "\n",
    "print( wave.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchaudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtransforms\u001b[39;00m \u001b[39mimport\u001b[39;00m Spectrogram, AmplitudeToDB\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000007?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m \n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000007?line=5'>6</a>\u001b[0m spec \u001b[39m=\u001b[39m Spectrogram( )(wave)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000007?line=6'>7</a>\u001b[0m spec \u001b[39m=\u001b[39m AmplitudeToDB()(spec)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000007?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(spec[\u001b[39m4\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py:124\u001b[0m, in \u001b[0;36mSpectrogram.forward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=113'>114</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, waveform: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=114'>115</a>\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=115'>116</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=116'>117</a>\u001b[0m \u001b[39m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=121'>122</a>\u001b[0m \u001b[39m        Fourier bins, and time is the number of window hops (n_frame).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=122'>123</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=123'>124</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mspectrogram(\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=124'>125</a>\u001b[0m         waveform,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=125'>126</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=126'>127</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=127'>128</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_fft,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=128'>129</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhop_length,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=129'>130</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwin_length,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=130'>131</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpower,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=131'>132</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnormalized,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=132'>133</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcenter,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=133'>134</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_mode,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=134'>135</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49monesided,\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/transforms.py?line=135'>136</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/functional/functional.py:98\u001b[0m, in \u001b[0;36mspectrogram\u001b[0;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized, center, pad_mode, onesided, return_complex)\u001b[0m\n\u001b[1;32m     <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/functional/functional.py?line=94'>95</a>\u001b[0m     waveform \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mpad(waveform, (pad, pad), \u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/functional/functional.py?line=96'>97</a>\u001b[0m \u001b[39m# pack batch\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/functional/functional.py?line=97'>98</a>\u001b[0m shape \u001b[39m=\u001b[39m waveform\u001b[39m.\u001b[39;49msize()\n\u001b[1;32m     <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/functional/functional.py?line=98'>99</a>\u001b[0m waveform \u001b[39m=\u001b[39m waveform\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    <a href='file:///home/luisbch/miniconda3/envs/mef/lib/python3.9/site-packages/torchaudio/functional/functional.py?line=100'>101</a>\u001b[0m \u001b[39m# default values are consistent with librosa.core.spectrum._spectrogram\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "from torchaudio.transforms import Spectrogram, AmplitudeToDB\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "\n",
    "spec = Spectrogram( )(wave)\n",
    "spec = AmplitudeToDB()(spec)\n",
    "\n",
    "plt.imshow(spec[4][0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "x = torch.arange(1., 11)\n",
    "x.unfold(0, 3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m x,y \u001b[39min\u001b[39;00m dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000009?line=2'>3</a>\u001b[0m   lengths\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000009?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mhist(lengths,bins\u001b[39m=\u001b[39m\u001b[39m25\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000009?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/luisbch/Documentos/ser/ser-benchmark/exploring_dataset.ipynb#ch0000009?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(lengths)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for x,y in dataset:\n",
    "  lengths.append(x.shape[0] )\n",
    "\n",
    "plt.hist(lengths,bins=25)\n",
    "\n",
    "import pandas as pd \n",
    "data = pd.DataFrame(lengths)\n",
    "data.describe()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "568ac6547d3d1fddd3c396d0a27c207536811ae3601b255860c3e0220053b898"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mef')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
